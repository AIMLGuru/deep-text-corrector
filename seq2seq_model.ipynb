{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47c6f5c4",
   "metadata": {
    "id": "47c6f5c4"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense,RNN,Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "import pickle\n",
    "import shutil\n",
    "from IPython.display import Image\n",
    "import io\n",
    "from nltk.translate.gleu_score import sentence_gleu\n",
    "from nltk.translate.bleu_score import sentence_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae3d7189",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ae3d7189",
    "outputId": "5737a7a3-085c-4369-8c2d-4db38a66b29d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#os.chdir('')\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "os.chdir('/content/drive/MyDrive/Deep Text Corrector')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "-pIopESOD6Yi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "-pIopESOD6Yi",
    "outputId": "0ad20e2f-474e-479a-fe57-873da03aec46"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/drive/MyDrive/Deep Text Corrector'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8f2580b",
   "metadata": {
    "id": "b8f2580b"
   },
   "outputs": [],
   "source": [
    "f = open('./data/perturbated_text_embed_matrix.pkl','rb')\n",
    "perturbated_text_embed_matrix = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('./data/text_embed_matrix.pkl','rb')\n",
    "text_embed_matrix = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('./data/perturbated_text_train.pkl','rb')\n",
    "perturbated_text_train = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('./data/text_inp_train.pkl','rb')\n",
    "text_inp_train = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('./data/text_out_train.pkl','rb')\n",
    "text_out_train = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('./data/perturbated_text_tokernizer_index.pkl','rb')\n",
    "perturbated_text_tokernizer_index = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('./data/text_inp_tokernizer_word_index.pkl','rb')\n",
    "text_inp_tokernizer_word_index = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('./data/text_inp_tokernizer.pkl','rb')\n",
    "text_inp_tokernizer = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('./data/train_data.pkl','rb')\n",
    "train_data = pickle.load(f)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7d43666",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f7d43666",
    "outputId": "b11b64da-bb5d-4512-9cd3-ff4835c5a5b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163668\n",
      "163668\n",
      "163668\n",
      "(163668, 20)\n",
      "(163668, 20)\n",
      "(163668, 20)\n",
      "34727\n",
      "34726\n"
     ]
    }
   ],
   "source": [
    "print(len(perturbated_text_train))\n",
    "print(len(text_inp_train))\n",
    "print(len(text_out_train))\n",
    "\n",
    "print(perturbated_text_train.shape)\n",
    "print(text_inp_train.shape)\n",
    "print(text_out_train.shape)\n",
    "\n",
    "print(len(text_embed_matrix))\n",
    "print(len(perturbated_text_embed_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29b85a8a",
   "metadata": {
    "id": "29b85a8a"
   },
   "outputs": [],
   "source": [
    "#https://edumunozsala.github.io/BlogEms/fastpages/jupyter/encoder-decoder/lstm/attention/tensorflow%202/2020/10/07/\n",
    "#Intro-seq2seq-Encoder-Decoder-ENG-SPA-translator-tf2.html\n",
    "\n",
    "#############################    Encoder    #######################################\n",
    "\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, input_vocab_size, embedding_dim, inp_len, lstm_units):\n",
    "        super().__init__()\n",
    "        self.input_vocab_size = input_vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.inp_len = inp_len\n",
    "        self.lstm_units= lstm_units\n",
    "        #self.lstm_output = 0\n",
    "        self.lstm_hidden_state=0\n",
    "        self.lstm_cell_state=0\n",
    "\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.embedding = Embedding(input_dim=self.input_vocab_size, output_dim=self.embedding_dim, input_length=self.inp_len,\n",
    "                           mask_zero=True, name=\"embedding_layer_encoder\", input_shape=(self.input_vocab_size,))\n",
    "        self.lstm = LSTM(self.lstm_units, return_state=True, return_sequences=True, name=\"Encoder\")\n",
    "\n",
    "        \n",
    "    def call(self, input_sentances, training=True):\n",
    "        input_embedd = self.embedding(input_sentances)\n",
    "        self.lstm_output, self.lstm_hidden_state,self.lstm_cell_state = self.lstm(input_embedd)\n",
    "        return self.lstm_output, self.lstm_hidden_state,self.lstm_cell_state\n",
    "    \n",
    "    \n",
    "    def get_states(self):\n",
    "        return self.lstm_hidden_state,self.lstm_cell_state\n",
    "\n",
    "#############################    Decoder    #######################################\n",
    "\n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, input_vocab_size, embedding_dim, inp_len, lstm_units):\n",
    "        super().__init__()\n",
    "        self.input_vocab_size = input_vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.lstm_units = lstm_units\n",
    "        self.inp_len = inp_len\n",
    "\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "   \n",
    "        self.embedding = Embedding(input_dim=self.input_vocab_size, output_dim=self.embedding_dim, input_length=self.inp_len,\n",
    "                                   mask_zero=True, name=\"embedding_layer_decoder\", weights=[text_embed_matrix],\n",
    "                                   input_shape=(self.input_vocab_size,))\n",
    "        self.lstm = LSTM(self.lstm_units, return_sequences=True, return_state=True, name=\"Decoder\")\n",
    "\n",
    "        \n",
    "    def call(self, target_sentances, state_h, state_c):\n",
    "        target_embedd = self.embedding(target_sentances)\n",
    "        lstm_output, _,_ = self.lstm(target_embedd, initial_state=[state_h, state_c])\n",
    "        return lstm_output\n",
    "\n",
    "#############################    EncoderDecoder    #######################################\n",
    "    \n",
    "class EncoderDecoder(Model):\n",
    "    def __init__(self, enc_inp_len, dec_inp_length, output_vocab_size, embedding_dim, lstm_units):\n",
    "        super().__init__() \n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.lstm_units = lstm_units\n",
    "        self.encoder = Encoder(input_vocab_size=len(perturbated_text_embed_matrix) , embedding_dim=embedding_dim, \n",
    "                               inp_len=enc_inp_len, lstm_units=lstm_units)\n",
    "        self.decoder = Decoder(input_vocab_size=len(text_embed_matrix) , embedding_dim=embedding_dim, \n",
    "                               inp_len=dec_inp_length, lstm_units=lstm_units)\n",
    "        self.dense   = Dense(output_vocab_size, activation='softmax')\n",
    "\n",
    "\n",
    "    def call(self, data):\n",
    "        input_ ,output = data[0], data[1]\n",
    "        encoder_output, encoder_h, encoder_c = self.encoder(input_)\n",
    "        decoder_output = self.decoder(output, encoder_h, encoder_c)\n",
    "        final_output = self.dense(decoder_output)\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c76dc04e",
   "metadata": {
    "id": "c76dc04e"
   },
   "outputs": [],
   "source": [
    "#https://edumunozsala.github.io/BlogEms/fastpages/jupyter/encoder-decoder/lstm/attention/tensorflow%202/2020/10/07/Intro-seq2seq-Encoder-Decoder-ENG-SPA-translator-tf2.ht\n",
    "loss_obj = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "def loss_func(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_value = loss_obj(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_value.dtype)\n",
    "    loss_value *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b290d41",
   "metadata": {
    "id": "4b290d41"
   },
   "outputs": [],
   "source": [
    "#from tensorflow.python.ops.clip_ops import clip_by_norm\n",
    "inp_vocab_size = len(perturbated_text_embed_matrix) \n",
    "out_vocab_size = len(text_embed_matrix) \n",
    "embedding_dim=300\n",
    "inp_length=20\n",
    "lstm_size=64\n",
    "batch_size=256\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(clipnorm=1.0)\n",
    "log_directory = os.getcwd()+\"/logs/seq2seq/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b3135f7",
   "metadata": {
    "id": "7b3135f7"
   },
   "outputs": [],
   "source": [
    "checkpoint_model = ModelCheckpoint(\"seq2seq_model_checkpoint.h5\", monitor='loss', save_best_only=True, save_weights_only=True, verbose=0, mode='min')\n",
    "earlystopping_model = EarlyStopping(monitor='loss', patience=5, verbose=1)\n",
    "tensorboard_model = TensorBoard(log_dir=log_directory)\n",
    "callbacks_model = [checkpoint_model, tensorboard_model, earlystopping_model]\n",
    "#callbacks_model=[tensorboard_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74d7ca4d",
   "metadata": {
    "id": "74d7ca4d",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = EncoderDecoder(enc_inp_len=inp_length,dec_inp_length=inp_length,output_vocab_size=len(text_embed_matrix), \n",
    "                       embedding_dim=embedding_dim, lstm_units=lstm_size )\n",
    "model.compile(optimizer=optimizer,loss=loss_func, metrics=['accuracy'])\n",
    "model.train_on_batch([perturbated_text_train[:batch_size],text_inp_train[:batch_size]],text_out_train[:batch_size])\n",
    "model.save_weights('seq2seq_model_weights', save_format='tf')\n",
    "#model.load_weights('seq2seq_model_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe2f3e8b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fe2f3e8b",
    "outputId": "c2bb6a19-199c-49d8-e872-9733f36d5d28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder_decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder (Encoder)           multiple                  10511240  \n",
      "                                                                 \n",
      " decoder (Decoder)           multiple                  10511540  \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  2257255   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,280,035\n",
      "Trainable params: 23,280,035\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b73710bb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b73710bb",
    "outputId": "687ad0c7-b19e-4f56-cd76-8e75bc2bac29",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "640/640 [==============================] - 100s 149ms/step - loss: 1.2361 - accuracy: 0.1180\n",
      "Epoch 2/10\n",
      "640/640 [==============================] - 95s 148ms/step - loss: 1.0194 - accuracy: 0.2292\n",
      "Epoch 3/10\n",
      "640/640 [==============================] - 94s 146ms/step - loss: 0.8369 - accuracy: 0.3653\n",
      "Epoch 4/10\n",
      "640/640 [==============================] - 93s 145ms/step - loss: 0.7259 - accuracy: 0.4497\n",
      "Epoch 5/10\n",
      "640/640 [==============================] - 93s 145ms/step - loss: 0.6456 - accuracy: 0.5097\n",
      "Epoch 6/10\n",
      "640/640 [==============================] - 93s 145ms/step - loss: 0.5882 - accuracy: 0.5494\n",
      "Epoch 7/10\n",
      "640/640 [==============================] - 93s 146ms/step - loss: 0.5436 - accuracy: 0.5792\n",
      "Epoch 8/10\n",
      "640/640 [==============================] - 92s 144ms/step - loss: 0.5064 - accuracy: 0.6033\n",
      "Epoch 9/10\n",
      "640/640 [==============================] - 92s 144ms/step - loss: 0.4748 - accuracy: 0.6233\n",
      "Epoch 10/10\n",
      "640/640 [==============================] - 92s 144ms/step - loss: 0.4472 - accuracy: 0.6407\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4f77ef7040>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=[perturbated_text_train,text_inp_train],y=text_out_train, epochs=10,batch_size=batch_size, callbacks=[callbacks_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "zr-m1NHMg7Yf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zr-m1NHMg7Yf",
    "outputId": "e6669a54-697c-4302-c28a-f3ee6bf58139"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "640/640 [==============================] - 93s 145ms/step - loss: 0.4227 - accuracy: 0.6558\n",
      "Epoch 2/20\n",
      "640/640 [==============================] - 92s 144ms/step - loss: 0.4011 - accuracy: 0.6687\n",
      "Epoch 3/20\n",
      "640/640 [==============================] - 92s 144ms/step - loss: 0.3813 - accuracy: 0.6804\n",
      "Epoch 4/20\n",
      "640/640 [==============================] - 93s 145ms/step - loss: 0.3632 - accuracy: 0.6909\n",
      "Epoch 5/20\n",
      "640/640 [==============================] - 92s 144ms/step - loss: 0.3466 - accuracy: 0.7007\n",
      "Epoch 6/20\n",
      "640/640 [==============================] - 93s 145ms/step - loss: 0.3311 - accuracy: 0.7095\n",
      "Epoch 7/20\n",
      "640/640 [==============================] - 93s 145ms/step - loss: 0.3172 - accuracy: 0.7180\n",
      "Epoch 8/20\n",
      "640/640 [==============================] - 92s 144ms/step - loss: 0.3035 - accuracy: 0.7258\n",
      "Epoch 9/20\n",
      "640/640 [==============================] - 92s 144ms/step - loss: 0.2907 - accuracy: 0.7338\n",
      "Epoch 10/20\n",
      "640/640 [==============================] - 94s 146ms/step - loss: 0.2785 - accuracy: 0.7410\n",
      "Epoch 11/20\n",
      "640/640 [==============================] - 93s 145ms/step - loss: 0.2673 - accuracy: 0.7485\n",
      "Epoch 12/20\n",
      "640/640 [==============================] - 94s 146ms/step - loss: 0.2565 - accuracy: 0.7554\n",
      "Epoch 13/20\n",
      "640/640 [==============================] - 92s 144ms/step - loss: 0.2464 - accuracy: 0.7623\n",
      "Epoch 14/20\n",
      "640/640 [==============================] - 92s 144ms/step - loss: 0.2367 - accuracy: 0.7690\n",
      "Epoch 15/20\n",
      "640/640 [==============================] - 93s 144ms/step - loss: 0.2276 - accuracy: 0.7761\n",
      "Epoch 16/20\n",
      "640/640 [==============================] - 92s 144ms/step - loss: 0.2189 - accuracy: 0.7826\n",
      "Epoch 17/20\n",
      "640/640 [==============================] - 92s 143ms/step - loss: 0.2108 - accuracy: 0.7889\n",
      "Epoch 18/20\n",
      "640/640 [==============================] - 92s 144ms/step - loss: 0.2027 - accuracy: 0.7953\n",
      "Epoch 19/20\n",
      "640/640 [==============================] - 92s 143ms/step - loss: 0.1953 - accuracy: 0.8013\n",
      "Epoch 20/20\n",
      "640/640 [==============================] - 92s 144ms/step - loss: 0.1885 - accuracy: 0.8069\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4f77ef7ca0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=[perturbated_text_train,text_inp_train],y=text_out_train, epochs=20,batch_size=batch_size, callbacks=[callbacks_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "-6zQvnl8qzV0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-6zQvnl8qzV0",
    "outputId": "182661c4-25ea-4cb6-8d47-e5abbd9e6888"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "640/640 [==============================] - 92s 143ms/step - loss: 0.1818 - accuracy: 0.8129\n",
      "Epoch 2/20\n",
      "640/640 [==============================] - 93s 145ms/step - loss: 0.1758 - accuracy: 0.8177\n",
      "Epoch 3/20\n",
      "640/640 [==============================] - 92s 144ms/step - loss: 0.1698 - accuracy: 0.8227\n",
      "Epoch 4/20\n",
      "640/640 [==============================] - 92s 144ms/step - loss: 0.1638 - accuracy: 0.8280\n",
      "Epoch 5/20\n",
      "640/640 [==============================] - 93s 145ms/step - loss: 0.1587 - accuracy: 0.8327\n",
      "Epoch 6/20\n",
      "640/640 [==============================] - 92s 143ms/step - loss: 0.1535 - accuracy: 0.8376\n",
      "Epoch 7/20\n",
      "640/640 [==============================] - 92s 144ms/step - loss: 0.1483 - accuracy: 0.8421\n",
      "Epoch 8/20\n",
      "640/640 [==============================] - 92s 144ms/step - loss: 0.1437 - accuracy: 0.8462\n",
      "Epoch 9/20\n",
      "640/640 [==============================] - 92s 144ms/step - loss: 0.1395 - accuracy: 0.8501\n",
      "Epoch 10/20\n",
      "640/640 [==============================] - 92s 144ms/step - loss: 0.1352 - accuracy: 0.8545\n",
      "Epoch 11/20\n",
      "640/640 [==============================] - 93s 145ms/step - loss: 0.1312 - accuracy: 0.8579\n",
      "Epoch 12/20\n",
      "640/640 [==============================] - 92s 144ms/step - loss: 0.1274 - accuracy: 0.8616\n",
      "Epoch 13/20\n",
      "640/640 [==============================] - 92s 144ms/step - loss: 0.1235 - accuracy: 0.8652\n",
      "Epoch 14/20\n",
      "640/640 [==============================] - 93s 145ms/step - loss: 0.1204 - accuracy: 0.8680\n",
      "Epoch 15/20\n",
      "640/640 [==============================] - 92s 144ms/step - loss: 0.1171 - accuracy: 0.8710\n",
      "Epoch 16/20\n",
      "640/640 [==============================] - 92s 144ms/step - loss: 0.1139 - accuracy: 0.8743\n",
      "Epoch 17/20\n",
      "640/640 [==============================] - 93s 145ms/step - loss: 0.1109 - accuracy: 0.8772\n",
      "Epoch 18/20\n",
      "640/640 [==============================] - 92s 144ms/step - loss: 0.1078 - accuracy: 0.8805\n",
      "Epoch 19/20\n",
      "640/640 [==============================] - 93s 145ms/step - loss: 0.1051 - accuracy: 0.8830\n",
      "Epoch 20/20\n",
      "640/640 [==============================] - 93s 145ms/step - loss: 0.1027 - accuracy: 0.8852\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4fa5edf790>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=[perturbated_text_train,text_inp_train],y=text_out_train, epochs=20,batch_size=batch_size, callbacks=[callbacks_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4114ee1",
   "metadata": {
    "id": "d4114ee1"
   },
   "outputs": [],
   "source": [
    "#tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ef68a2dc",
   "metadata": {
    "id": "ef68a2dc"
   },
   "outputs": [],
   "source": [
    "def EncoderOutput(encoder_input):\n",
    "    enc_input=list()\n",
    "    for word in encoder_input.split():\n",
    "        if perturbated_text_tokernizer_index.get(word) != None:\n",
    "            enc_input.append(perturbated_text_tokernizer_index.get(word))\n",
    "        else:\n",
    "            enc_input.append(0)\n",
    "            \n",
    "    enc_output, enc_hidden_state, enc_cell_state = model.layers[0](np.array([enc_input], dtype='int32'))\n",
    "    \n",
    "    return enc_output, enc_hidden_state, enc_cell_state\n",
    "\n",
    "def PredictOutput(encoder_input, decoder_input):\n",
    "\n",
    "    dec_input=list()\n",
    "    for word in decoder_input.split():\n",
    "        if text_inp_tokernizer_word_index.get(word) != None:\n",
    "            dec_input.append(text_inp_tokernizer_word_index.get(word))\n",
    "        else:\n",
    "            dec_input.append(0)\n",
    "    \n",
    "    enc_output, enc_hidden_state, enc_cell_state=EncoderOutput(encoder_input)\n",
    "    \n",
    "    pred = model.layers[2](model.layers[1](np.array([dec_input], dtype='int32'),\n",
    "                                                                  enc_hidden_state, enc_cell_state))\n",
    "    transalated_output=\"\"\n",
    "    for word in pred[0]:\n",
    "        word = text_inp_tokernizer.index_word[tf.argmax(word).numpy()]\n",
    "        transalated_output += word + \" \"\n",
    "    \n",
    "    return transalated_output\n",
    "\n",
    "def InferResults(data):\n",
    "    output = []\n",
    "\n",
    "    for enc_inp,dec_inp, dec_out in data.values:\n",
    "        pred = PredictOutput(enc_inp,dec_inp)\n",
    "        output.append(pred)\n",
    "\n",
    "    data['correct_output'] = data['dec_out']\n",
    "    data['predicted_output'] = output\n",
    "\n",
    "    data = data.drop(['dec_inp', 'dec_out'], axis=1)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a45aa805",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "a45aa805",
    "outputId": "5c78302d-ae6c-4598-c9a3-ebf4325aa286"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-f7d4a598-1f1b-4d01-8db8-3967f2dfe12c\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enc_inp</th>\n",
       "      <th>correct_output</th>\n",
       "      <th>predicted_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106784</th>\n",
       "      <td>was dying and i cannot deal with it</td>\n",
       "      <td>he is dying and i cannot deal with it eos</td>\n",
       "      <td>is is and and i cannot deal with it eos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21949</th>\n",
       "      <td>we are still venting trace gasses gimme twenty...</td>\n",
       "      <td>we are still venting trace gasses gimme twenty...</td>\n",
       "      <td>we are still venting trace gasses gimme twenty...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82855</th>\n",
       "      <td>what about luca sollozzo did not seem worried ...</td>\n",
       "      <td>what about luca sollozzo did not seem worried ...</td>\n",
       "      <td>what about luca sollozzo did not seem worried ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>no i never did either</td>\n",
       "      <td>no i never did either eos</td>\n",
       "      <td>no i never did either eos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119530</th>\n",
       "      <td>i am thinking of your man</td>\n",
       "      <td>i am thinking of your man eos</td>\n",
       "      <td>i am thinking of your man eos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86473</th>\n",
       "      <td>yes there i would like to go up</td>\n",
       "      <td>yes there is i would like to go up eos</td>\n",
       "      <td>yes i i to would like to go up eos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70201</th>\n",
       "      <td>get hot mug of chocolate first thing i gonna do</td>\n",
       "      <td>get a hot mug of chocolate first thing i am go...</td>\n",
       "      <td>get a hot couple of working first time i am go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215591</th>\n",
       "      <td>no i saw it on his face</td>\n",
       "      <td>no i saw it on his face eos</td>\n",
       "      <td>no i saw it on his face eos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30683</th>\n",
       "      <td>i want to be alone</td>\n",
       "      <td>i want to be alone eos</td>\n",
       "      <td>i want to be alone eos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104140</th>\n",
       "      <td>whatever you need whatever jamie needs i am he...</td>\n",
       "      <td>whatever you need whatever jamie needs i am he...</td>\n",
       "      <td>whatever you need whatever i gets i was i they...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f7d4a598-1f1b-4d01-8db8-3967f2dfe12c')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-f7d4a598-1f1b-4d01-8db8-3967f2dfe12c button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-f7d4a598-1f1b-4d01-8db8-3967f2dfe12c');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                  enc_inp  \\\n",
       "106784                was dying and i cannot deal with it   \n",
       "21949   we are still venting trace gasses gimme twenty...   \n",
       "82855   what about luca sollozzo did not seem worried ...   \n",
       "1378                                no i never did either   \n",
       "119530                          i am thinking of your man   \n",
       "86473                     yes there i would like to go up   \n",
       "70201     get hot mug of chocolate first thing i gonna do   \n",
       "215591                            no i saw it on his face   \n",
       "30683                                  i want to be alone   \n",
       "104140  whatever you need whatever jamie needs i am he...   \n",
       "\n",
       "                                           correct_output  \\\n",
       "106784          he is dying and i cannot deal with it eos   \n",
       "21949   we are still venting trace gasses gimme twenty...   \n",
       "82855   what about luca sollozzo did not seem worried ...   \n",
       "1378                            no i never did either eos   \n",
       "119530                      i am thinking of your man eos   \n",
       "86473              yes there is i would like to go up eos   \n",
       "70201   get a hot mug of chocolate first thing i am go...   \n",
       "215591                        no i saw it on his face eos   \n",
       "30683                              i want to be alone eos   \n",
       "104140  whatever you need whatever jamie needs i am he...   \n",
       "\n",
       "                                         predicted_output  \n",
       "106784           is is and and i cannot deal with it eos   \n",
       "21949   we are still venting trace gasses gimme twenty...  \n",
       "82855   what about luca sollozzo did not seem worried ...  \n",
       "1378                           no i never did either eos   \n",
       "119530                     i am thinking of your man eos   \n",
       "86473                 yes i i to would like to go up eos   \n",
       "70201   get a hot couple of working first time i am go...  \n",
       "215591                       no i saw it on his face eos   \n",
       "30683                             i want to be alone eos   \n",
       "104140  whatever you need whatever i gets i was i they...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data_train=train_data.sample(100)\n",
    "results=InferResults(sample_data_train)\n",
    "results.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "Rv9y3_l2UCm6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rv9y3_l2UCm6",
    "outputId": "712f87f1-85a8-4b20-c5be-167c0245a168"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['oh come on', 'oh come on eos', 'oh come on eos '], dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.values[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2IrP7WhMOkRf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2IrP7WhMOkRf",
    "outputId": "24badf76-9f36-45fa-a795-353e222497b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score of train dataset is 0.7996630746957749\n"
     ]
    }
   ],
   "source": [
    "train_output_bleu_score = []\n",
    "for encoder_input_data, correct_output , predicted_output in results.values:\n",
    "    correct_output = correct_output.split()\n",
    "    predicted_output = predicted_output.rstrip().split()\n",
    "    if len(correct_output) == len(predicted_output):\n",
    "        train_output_bleu_score.append(sentence_bleu([correct_output],predicted_output))\n",
    "print(\"BLEU Score of train dataset is\",sum(train_output_bleu_score)/len(train_output_bleu_score))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
