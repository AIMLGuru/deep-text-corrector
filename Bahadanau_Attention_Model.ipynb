{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47c6f5c4",
   "metadata": {
    "id": "47c6f5c4"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense,RNN,Flatten, Softmax\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau\n",
    "from tensorflow.keras import initializers, regularizers, constraints\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "import pickle\n",
    "import shutil\n",
    "from IPython.display import Image\n",
    "import io\n",
    "from nltk.translate.bleu_score import sentence_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "rjrWmSA346Zn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "rjrWmSA346Zn",
    "outputId": "f5e5eaab-a41b-4621-8bdb-f5c1e5d7096d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "print(tf. __version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60e40f0b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "60e40f0b",
    "outputId": "33df6aa4-765c-44ce-fe4f-acac17c1a02e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.10\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae3d7189",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "ae3d7189",
    "outputId": "b6aee325-9b19-4e1c-b8b2-dcfa19ac10e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "os.chdir('/content/drive/MyDrive/AI/Datasets/Deep Text Corrector')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "-pIopESOD6Yi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "-pIopESOD6Yi",
    "outputId": "3ee42c16-b29c-40a7-9a09-a0bd036618dd"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/drive/MyDrive/AI/Datasets/Deep Text Corrector'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8f2580b",
   "metadata": {
    "id": "b8f2580b"
   },
   "outputs": [],
   "source": [
    "f = open('./data/perturbated_text_embed_matrix.pkl','rb')\n",
    "perturbated_text_embed_matrix = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('./data/text_embed_matrix.pkl','rb')\n",
    "text_embed_matrix = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('./data/perturbated_text_train.pkl','rb')\n",
    "perturbated_text_train = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('./data/text_inp_train.pkl','rb')\n",
    "text_inp_train = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('./data/text_out_train.pkl','rb')\n",
    "text_out_train = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('./data/perturbated_text_tokernizer_index.pkl','rb')\n",
    "perturbated_text_tokernizer_index = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('./data/text_inp_tokernizer_word_index.pkl','rb')\n",
    "text_inp_tokernizer_word_index = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('./data/perturbated_text_tokernizer.pkl','rb')\n",
    "perturbated_text_tokernizer = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "\n",
    "f = open('./data/text_inp_tokernizer.pkl','rb')\n",
    "text_inp_tokernizer = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "train_data = pd.read_csv('./data/train_data.csv', usecols=['enc_inp', 'dec_inp', 'dec_out'])\n",
    "test_data = pd.read_csv('./data/test_data.csv', usecols=['enc_inp', 'dec_inp', 'dec_out'])\n",
    "validation_data = pd.read_csv('./data/validation_data.csv', usecols=['enc_inp', 'dec_inp', 'dec_out'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5301521b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "5301521b",
    "outputId": "771e67d5-dc61-47c2-d676-dec113cda73b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-78d6f748-828d-423e-9df7-a24434c3246f\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enc_inp</th>\n",
       "      <th>dec_inp</th>\n",
       "      <th>dec_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fred fred  actually  been on an extended vacat...</td>\n",
       "      <td>sos fred fred he is actually he is been on an ...</td>\n",
       "      <td>fred fred he is actually he is been on an exte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no funniest show that mickey and i ever did  o...</td>\n",
       "      <td>sos no the funniest show that mickey and i eve...</td>\n",
       "      <td>no the funniest show that mickey and i ever di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>do not send flowers joe i am not dead yet</td>\n",
       "      <td>sos do not send flowers joe i am not dead yet</td>\n",
       "      <td>do not send flowers joe i am not dead yet eos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>idea was out there in universe now what</td>\n",
       "      <td>sos the idea was out there in the universe now...</td>\n",
       "      <td>the idea was out there in the universe now wha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i do not recommend it</td>\n",
       "      <td>sos i do not recommend it</td>\n",
       "      <td>i do not recommend it eos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163663</th>\n",
       "      <td>you know sometimes people can surprise you som...</td>\n",
       "      <td>sos you know sometimes people can surprise you...</td>\n",
       "      <td>you know sometimes people can surprise you som...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163664</th>\n",
       "      <td>yeah chili hi you are fifty feet in the air</td>\n",
       "      <td>sos yeah chili hi you are fifty feet in the air</td>\n",
       "      <td>yeah chili hi you are fifty feet in the air eos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163665</th>\n",
       "      <td>incredible the cloth the buttons it looks to b...</td>\n",
       "      <td>sos incredible the cloth the buttons it looks ...</td>\n",
       "      <td>incredible the cloth the buttons it looks to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163666</th>\n",
       "      <td>it is not me moron</td>\n",
       "      <td>sos it is not me moron</td>\n",
       "      <td>it is not me moron eos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163667</th>\n",
       "      <td>when i reach ten then i will start with you</td>\n",
       "      <td>sos when i reach ten then i will start with you</td>\n",
       "      <td>when i reach ten then i will start with you eos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163668 rows Ã— 3 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-78d6f748-828d-423e-9df7-a24434c3246f')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-78d6f748-828d-423e-9df7-a24434c3246f button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-78d6f748-828d-423e-9df7-a24434c3246f');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                  enc_inp  \\\n",
       "0       fred fred  actually  been on an extended vacat...   \n",
       "1       no funniest show that mickey and i ever did  o...   \n",
       "2               do not send flowers joe i am not dead yet   \n",
       "3                 idea was out there in universe now what   \n",
       "4                                   i do not recommend it   \n",
       "...                                                   ...   \n",
       "163663  you know sometimes people can surprise you som...   \n",
       "163664        yeah chili hi you are fifty feet in the air   \n",
       "163665  incredible the cloth the buttons it looks to b...   \n",
       "163666                                 it is not me moron   \n",
       "163667        when i reach ten then i will start with you   \n",
       "\n",
       "                                                  dec_inp  \\\n",
       "0       sos fred fred he is actually he is been on an ...   \n",
       "1       sos no the funniest show that mickey and i eve...   \n",
       "2           sos do not send flowers joe i am not dead yet   \n",
       "3       sos the idea was out there in the universe now...   \n",
       "4                               sos i do not recommend it   \n",
       "...                                                   ...   \n",
       "163663  sos you know sometimes people can surprise you...   \n",
       "163664    sos yeah chili hi you are fifty feet in the air   \n",
       "163665  sos incredible the cloth the buttons it looks ...   \n",
       "163666                             sos it is not me moron   \n",
       "163667    sos when i reach ten then i will start with you   \n",
       "\n",
       "                                                  dec_out  \n",
       "0       fred fred he is actually he is been on an exte...  \n",
       "1       no the funniest show that mickey and i ever di...  \n",
       "2           do not send flowers joe i am not dead yet eos  \n",
       "3       the idea was out there in the universe now wha...  \n",
       "4                               i do not recommend it eos  \n",
       "...                                                   ...  \n",
       "163663  you know sometimes people can surprise you som...  \n",
       "163664    yeah chili hi you are fifty feet in the air eos  \n",
       "163665  incredible the cloth the buttons it looks to b...  \n",
       "163666                             it is not me moron eos  \n",
       "163667    when i reach ten then i will start with you eos  \n",
       "\n",
       "[163668 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7d43666",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "f7d43666",
    "outputId": "ecd6b423-f260-4a96-cfe4-ddc401823aa2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163668\n",
      "163668\n",
      "163668\n",
      "(163668, 20)\n",
      "(163668, 20)\n",
      "(163668, 20)\n",
      "34604\n",
      "34602\n"
     ]
    }
   ],
   "source": [
    "print(len(perturbated_text_train))\n",
    "print(len(text_inp_train))\n",
    "print(len(text_out_train))\n",
    "\n",
    "print(perturbated_text_train.shape)\n",
    "print(text_inp_train.shape)\n",
    "print(text_out_train.shape)\n",
    "\n",
    "print(len(text_embed_matrix))\n",
    "print(len(perturbated_text_embed_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b73ed96a",
   "metadata": {
    "id": "b73ed96a"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    '''\n",
    "    Encoder- Takes a input sequence and returns output sequence\n",
    "    '''\n",
    "    def __init__(self,input_vocab_size,embedd_size,lstm_size,inp_len):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_vocab_size = input_vocab_size\n",
    "        self.embedd_size = embedd_size\n",
    "        self.lstm_size = lstm_size\n",
    "        self.inp_len = inp_len\n",
    "\n",
    "        self.embedd = Embedding(input_dim = self.input_vocab_size, output_dim = self.embedd_size, input_length=self.inp_len,\n",
    "                                weights = [perturbated_text_embed_matrix], mask_zero=True)\n",
    "        self.encoder_lstm = LSTM(units = self.lstm_size, return_sequences=True, return_state=True, \n",
    "                               name=\"Encoder\", kernel_regularizer= regularizers.l2(1e-5))\n",
    "\n",
    "    def call(self,inp_seq, training=True):\n",
    "        embedds = self.embedd(inp_seq)\n",
    "        encoder_output, encoder_hidden_state, encod_cell_state = self.encoder_lstm(embedds)\n",
    "        return encoder_output, encoder_hidden_state, encod_cell_state\n",
    "\n",
    "    def initialize_states(self,batch_size):\n",
    "        h_state = np.zeros((batch_size, self.lstm_units))\n",
    "        c_state = np.zeros((batch_size, self.lstm_units))\n",
    "        return h_state, c_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a3c6528",
   "metadata": {
    "id": "6a3c6528"
   },
   "outputs": [],
   "source": [
    "#https://github.com/UdiBhaskar/TfKeras-Custom-Layers/blob/master/Seq2Seq/clayers.py\n",
    "class MonotonicBahadanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units,\n",
    "                 return_aweights=False,\n",
    "                 scaling_fact=None,\n",
    "                 noise_std=0,\n",
    "                 weights_inits='he_normal',\n",
    "                 bias_inits='zeros',\n",
    "                 **kwargs):\n",
    "        \n",
    "        if 'name' not in kwargs:\n",
    "            kwargs['name'] = \"\"\n",
    "            \n",
    "        super(MonotonicBahadanauAttention, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.scaling_fact = scaling_fact\n",
    "        self.noise_std = noise_std\n",
    "        self.weights_inits = initializers.get(weights_inits)\n",
    "        self.bias_inits = initializers.get(bias_inits)\n",
    "        self.weights_regs = regularizers.l2(1e-2)\n",
    "    \n",
    "    def build(self, inp_shape):\n",
    "        self._wa = layers.Dense(self.units, use_bias=False,\\\n",
    "            kernel_inits=self.weights_inits, bias_inits=self.bias_inits,\\\n",
    "                kernel_regs= self.weights_regs, name=self.name+\"Wa\")\n",
    "        \n",
    "        self._ua = layers.Dense(self.units,\\\n",
    "            kernel_inits=self.weights_inits, bias_inits=self.bias_inits,\\\n",
    "                kernel_regs= self.weights_regs, name=self.name+\"Ua\")\n",
    "        \n",
    "        self._va = layers.Dense(1, use_bias=False, kernel_inits=self.weights_inits,\\\n",
    "            kernel_regs= self.weights_regs,bias_inits=self.bias_inits, name=self.name+\"Va\")\n",
    "        \n",
    "        \n",
    "    def call(self, dec_h_state, enc_out, previous_attention, training=True):\n",
    "\n",
    "        enc_out, dec_h_state = tf.cast(enc_out, tf.float32), \\\n",
    "            tf.cast(dec_h_state, tf.float32)\n",
    "        \n",
    "        dec_h_with_time_axis = tf.expand_dims(dec_h_state, 1)\n",
    "\n",
    "        weight_wa=self._wa\n",
    "        weight_ua=self._ua\n",
    "        weight_va=self._va\n",
    "        \n",
    "        #bahdanau attention score\n",
    "        score = weight_va(tf.nn.tanh(weight_wa(dec_h_with_time_axis) + weight_ua(enc_out)))\n",
    "        score = tf.squeeze(score, [2])\n",
    "        \n",
    "        if self.scaling_fact is not None:\n",
    "            score = score/tf.sqrt(self.scaling_fact)\n",
    "\n",
    "        if training:\n",
    "            if self.noise_std > 0:\n",
    "                random_noise = tf.random.normal(shape=tf.shape(input=score), mean=0,\\\n",
    "                    stddev=self.noise_std, dtype=score.dtype, seed=self.seed)\n",
    "                score = score + random_noise\n",
    "\n",
    "        probs = tf.sigmoid(score)\n",
    "\n",
    "        #monotonic attention 'parallel' mode\n",
    "        cumprod_1mp_probs = tf.exp(tf.cumsum(tf.math.log(tf.clip_by_value(1-probs,\\\n",
    "            1e-10, 1)), axis=1, exclusive=True))\n",
    "        att_weights = probs*cumprod_1mp_probs*tf.cumsum(previous_attention/\\\n",
    "            tf.clip_by_value(cumprod_1mp_probs, 1e-10, 1.), axis=1)\n",
    "        att_weights = tf.expand_dims(att_weights, 1)\n",
    "\n",
    "        contxt_vec = tf.matmul(att_weights, enc_out)\n",
    "        contxt_vec = tf.squeeze(contxt_vec, 1, name=\"contxt_vec\")\n",
    "\n",
    "        return contxt_vec, tf.squeeze(att_weights, 1, name='att_weights')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4624dc9",
   "metadata": {
    "id": "c4624dc9"
   },
   "outputs": [],
   "source": [
    "class OneStepDecoder(tf.keras.Model):\n",
    "\n",
    "    def __init__(self,target_vocab_size, embedd_dim, inp_len, decoder_units, attention_units):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.target_vocab_size = target_vocab_size\n",
    "        self.embedd_dim = embedd_dim\n",
    "        self.inp_len = inp_len\n",
    "        self.decoder_units = decoder_units\n",
    "        self.attention_units = attention_units\n",
    "        \n",
    "        self.decoder_embedding_layer = Embedding(input_dim = self.target_vocab_size, output_dim = self.embedd_dim,\n",
    "                                                 input_length = self.inp_len,\n",
    "                                      weights = [text_embed_matrix] , name=\"onestepdecoder_embedding_layer\", mask_zero=True)\n",
    "        \n",
    "        self.decoder_LSTM = LSTM(units = self.decoder_units, return_state=True, kernel_regularizer= regularizers.l2(1e-5))\n",
    "        \n",
    "        self.MonotonicBahadanauAttention=MonotonicBahadanauAttention(self.attention_units,\n",
    "                 return_aweights=False,\n",
    "                 scaling_factor=None,\n",
    "                 noise_std=0,\n",
    "                 weights_initializer='he_normal',\n",
    "                 bias_initializer='zeros',)\n",
    "\n",
    "        self.dense = Dense(units=self.target_vocab_size)\n",
    "\n",
    "    def call(self,inp_to_dec, encoder_output, state_hidden, state_cell, att_weights):\n",
    "        \n",
    "        decoder_embedd = self.decoder_embedding_layer(inp_to_dec)\n",
    "        context_vec, att_weights = self.MonotonicBahadanauAttention(state_hidden,encoder_output, att_weights)\n",
    "        decoder_embedd = tf.concat([tf.expand_dims(context_vec,1), decoder_embedd], axis=-1)\n",
    "        decoder_out, decoder_hidden_state, decoder_cell_state = self.decoder_LSTM(decoder_embedd, \n",
    "                                                                                initial_state=[state_hidden, state_cell])\n",
    "        onestep_decoder_output = self.dense(decoder_out)\n",
    "\n",
    "        return onestep_decoder_output, decoder_hidden_state, decoder_cell_state, att_weights, context_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbd0904c",
   "metadata": {
    "id": "cbd0904c"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self,output_vocab_size, embedd_dim, output_length, decoder_units , att_units):\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_vocab_size = output_vocab_size\n",
    "        self.embedd_dim = embedd_dim\n",
    "        self.output_length = output_length\n",
    "        self.decoder_units = decoder_units\n",
    "        self.att_units = att_units\n",
    "\n",
    "        self.onestep_decoder = OneStepDecoder(self.output_vocab_size, self.embedd_dim, self.output_length, self.decoder_units\n",
    "                                              ,self.att_units)\n",
    "\n",
    "        \n",
    "    def call(self, inp_to_dec,enc_out,decoder_h,decoder_c, att_weights ):\n",
    "\n",
    "        total_out = tf.TensorArray(tf.float32, size=tf.shape(inp_to_dec)[1], name='out_arrays')\n",
    "        i = tf.shape(inp_to_dec)[1]\n",
    "\n",
    "        for t_step in range(i):    \n",
    "\n",
    "            onestep_decoder_output, decoder_h, decoder_c, att_weights, context_vector = self.onestep_decoder(\n",
    "                                            inp_to_dec[:, t_step:t_step+1], enc_out, decoder_h, decoder_c, att_weights)\n",
    "\n",
    "            total_out = total_out.write(t_step, onestep_decoder_output)\n",
    "        \n",
    "        total_out = tf.transpose(total_out.stack(), [1,0,2])\n",
    "\n",
    "        return total_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb67bfd9",
   "metadata": {
    "id": "eb67bfd9"
   },
   "outputs": [],
   "source": [
    "class bahadanau_attention_model(tf.keras.Model):\n",
    "    def __init__(self,encoder_vocab_size, decoder_vocab_size, encoder_embedd_dim, decoder_embedd_dim, input_len, output_len, \n",
    "                 encoder_units, decoder_units, attention_units):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder_vocab_size = encoder_vocab_size\n",
    "        self.decoder_vocab_size = decoder_vocab_size\n",
    "        self.encoder_embedd_dim = encoder_embedd_dim\n",
    "        self.decoder_embedd_dim = decoder_embedd_dim\n",
    "        self.input_len = input_len\n",
    "        self.output_len = output_len\n",
    "        self.encoder_units = encoder_units\n",
    "        self.decoder_units = decoder_units\n",
    "        self.attention_units = attention_units\n",
    "\n",
    "        self.encoder = Encoder(self.encoder_vocab_size,self.encoder_embedd_dim,self.encoder_units,self.input_len)\n",
    "        self.decoder = Decoder(self.decoder_vocab_size,self.decoder_embedd_dim,self.output_len,self.decoder_units,\n",
    "                               self.attention_units)\n",
    "\n",
    "    def call(self, data, training=True):\n",
    "        encoder_inp, decoder_inp = data[0], data[1]\n",
    "        \n",
    "        encoder_out, encoder_h, encoder_c = self.encoder(encoder_inp)\n",
    "    \n",
    "        decoder_h = encoder_h  #initial decoder state is equal to final encoder hidden state\n",
    "        decoder_c = encoder_c\n",
    "\n",
    "        att_weights = np.zeros((512, 20), dtype='float32')\n",
    "        att_weights[:, 0] = 1\n",
    "        \n",
    "        final_output = self.decoder(decoder_inp,encoder_out,decoder_h,decoder_c, att_weights)\n",
    "        return final_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c58f5ed7",
   "metadata": {
    "id": "c58f5ed7"
   },
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, data, perturbed_tkn, corr_tkn, max_len):\n",
    "        self.enc_inputs = data['enc_inp'].values\n",
    "        self.dec_inputs = data['dec_inp'].values\n",
    "        self.dec_outputs = data['dec_out'].values\n",
    "        self.corr_tkn = text_inp_tokernizer\n",
    "        self.perturbed_tkn = perturbated_text_tokernizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        #self.enc_sequence = self.perturbed_tkn.texts_to_sequences([self.enc_inputs[i]]) # need to pass list of values\n",
    "        #self.dec_input_sequence = self.corr_tkn.texts_to_sequences([self.dec_inputs[i]])\n",
    "        #self.dec_output_sequence = self.corr_tkn.texts_to_sequences([self.dec_outputs[i]])\n",
    "\n",
    "        #self.enc_sequence = pad_sequences(self.enc_sequence, maxlen=self.max_len, dtype='float32', padding='post')\n",
    "        #self.dec_input_sequence = pad_sequences(self.dec_input_sequence, maxlen=self.max_len, dtype='float32', padding='post')\n",
    "        #self.dec_output_sequence = pad_sequences(self.dec_output_sequence, maxlen=self.max_len, dtype='float32', padding='post')\n",
    "          \n",
    "        self.enc_sequence=[perturbated_text_train[i]]\n",
    "        self.dec_input_sequence=[text_inp_train[i]]\n",
    "        self.dec_output_sequence=[text_out_train[i]]\n",
    "        \n",
    "        return self.enc_sequence, self.dec_input_sequence, self.dec_output_sequence\n",
    "\n",
    "    def __len__(self): # your model.fit_gen requires this function\n",
    "        return len(self.enc_inputs)\n",
    "    \n",
    "class Dataloader(tf.keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, data, batch_size=1):\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.indices = np.arange(len(self.data.enc_inputs))\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        begin = i * self.batch_size\n",
    "        end = (i + 1) * self.batch_size\n",
    "        data_sequence= []\n",
    "        for j in range(begin, end):\n",
    "            data_sequence.append(self.data[j])\n",
    "\n",
    "        batch = [np.squeeze(np.stack(seq, axis=1), axis=0) for seq in zip(*data_sequence)]\n",
    "        \n",
    "        return [batch[0],batch[1]],batch[2]\n",
    "\n",
    "    def __len__(self):  # your model.fit_gen requires this function\n",
    "        return len(self.indices) // self.batch_size\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indices = np.random.permutation(self.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83fd8879",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "83fd8879",
    "outputId": "18b64ec5-5e1d-4bdc-cf59-640321011bf0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 20) (512, 20) (512, 20)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "train_data_padded = Dataset(train_data, perturbated_text_tokernizer_index, text_inp_tokernizer, 20)\n",
    "validation_data_padded  = Dataset(validation_data, perturbated_text_tokernizer_index, text_inp_tokernizer, 20)\n",
    "test_data_padded = Dataset(test_data, perturbated_text_tokernizer_index, text_inp_tokernizer, 20)\n",
    "\n",
    "batch_train_data = Dataloader(train_data_padded, batch_size=512)\n",
    "batch_validation_data = Dataloader(validation_data_padded, batch_size=512)\n",
    "batch_test_data = Dataloader(test_data_padded, batch_size=512)\n",
    "\n",
    "print(batch_train_data[0][0][0].shape, batch_train_data[0][0][1].shape, batch_train_data[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e023a007",
   "metadata": {
    "id": "e023a007"
   },
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1206816",
   "metadata": {
    "id": "b1206816"
   },
   "outputs": [],
   "source": [
    "encoder_vocab_size = len(perturbated_text_embed_matrix)\n",
    "decoder_vocab_size = len(text_embed_matrix) \n",
    "encoder_embedd_dim = 300\n",
    "decoder_embedd_dim = 300\n",
    "input_len = 20\n",
    "output_len = 20\n",
    "encoder_units = 256\n",
    "decoder_units = 256\n",
    "att_units = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "s4Ht-uAUEM4r",
   "metadata": {
    "id": "s4Ht-uAUEM4r"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(clipnorm=1)\n",
    "log_directory = os.getcwd() + '/bahadanau_attention_model/logs/fit/' + str(datetime.datetime.now())\n",
    "checkpoint_model = ModelCheckpoint(\"bahadanau_attention_model_weights_\"+ str(datetime.datetime.now())+\".hdf5\", \n",
    "                                   monitor='loss', save_best_only=True, save_weights_only=True, verbose=0, mode='min')\n",
    "earlystopping_model = EarlyStopping(monitor='loss', patience=10, verbose=1)\n",
    "tensorboard = TensorBoard(log_dir=log_directory, histogram_freq=1)\n",
    "callbacks_model = [checkpoint_model, tensorboard, earlystopping_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cd38e406",
   "metadata": {
    "id": "cd38e406"
   },
   "outputs": [],
   "source": [
    "model = bahadanau_attention_model(encoder_vocab_size, decoder_vocab_size, encoder_embedd_dim, decoder_embedd_dim, \n",
    "                              input_len, output_len, encoder_units, decoder_units ,att_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6e42e96d",
   "metadata": {
    "id": "6e42e96d"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd73f9f1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "cd73f9f1",
    "outputId": "16a63aa3-4c7c-41b5-e4b5-a8feae46e79b",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "319/319 [==============================] - 269s 773ms/step - loss: 4.3607 - accuracy: 0.0647 - val_loss: 2.4700 - val_accuracy: 0.0717\n",
      "Epoch 2/20\n",
      "319/319 [==============================] - 222s 697ms/step - loss: 2.2582 - accuracy: 0.1004 - val_loss: 2.0626 - val_accuracy: 0.1246\n",
      "Epoch 3/20\n",
      "319/319 [==============================] - 228s 716ms/step - loss: 1.8915 - accuracy: 0.1511 - val_loss: 1.6988 - val_accuracy: 0.1844\n",
      "Epoch 4/20\n",
      "319/319 [==============================] - 223s 698ms/step - loss: 1.4642 - accuracy: 0.2299 - val_loss: 1.2559 - val_accuracy: 0.2709\n",
      "Epoch 5/20\n",
      "319/319 [==============================] - 225s 704ms/step - loss: 1.0958 - accuracy: 0.3003 - val_loss: 0.9536 - val_accuracy: 0.3235\n",
      "Epoch 6/20\n",
      "319/319 [==============================] - 224s 702ms/step - loss: 0.8701 - accuracy: 0.3371 - val_loss: 0.7715 - val_accuracy: 0.3506\n",
      "Epoch 7/20\n",
      "319/319 [==============================] - 226s 707ms/step - loss: 0.7065 - accuracy: 0.3612 - val_loss: 0.6269 - val_accuracy: 0.3721\n",
      "Epoch 8/20\n",
      "319/319 [==============================] - 224s 701ms/step - loss: 0.5917 - accuracy: 0.3762 - val_loss: 0.5291 - val_accuracy: 0.3845\n",
      "Epoch 9/20\n",
      "319/319 [==============================] - 224s 703ms/step - loss: 0.4993 - accuracy: 0.3881 - val_loss: 0.4689 - val_accuracy: 0.3913\n",
      "Epoch 10/20\n",
      "319/319 [==============================] - 222s 695ms/step - loss: 0.4312 - accuracy: 0.3965 - val_loss: 0.3963 - val_accuracy: 0.4002\n",
      "Epoch 11/20\n",
      "319/319 [==============================] - 223s 699ms/step - loss: 0.3750 - accuracy: 0.4035 - val_loss: 0.3449 - val_accuracy: 0.4072\n",
      "Epoch 12/20\n",
      "319/319 [==============================] - 224s 702ms/step - loss: 0.3304 - accuracy: 0.4091 - val_loss: 0.3091 - val_accuracy: 0.4122\n",
      "Epoch 13/20\n",
      "319/319 [==============================] - 221s 694ms/step - loss: 0.2996 - accuracy: 0.4129 - val_loss: 0.2731 - val_accuracy: 0.4178\n",
      "Epoch 14/20\n",
      "319/319 [==============================] - 221s 693ms/step - loss: 0.2627 - accuracy: 0.4183 - val_loss: 0.2547 - val_accuracy: 0.4206\n",
      "Epoch 15/20\n",
      "319/319 [==============================] - 226s 710ms/step - loss: 0.2340 - accuracy: 0.4225 - val_loss: 0.2186 - val_accuracy: 0.4267\n",
      "Epoch 16/20\n",
      "319/319 [==============================] - 222s 697ms/step - loss: 0.2106 - accuracy: 0.4265 - val_loss: 0.2012 - val_accuracy: 0.4300\n",
      "Epoch 17/20\n",
      "319/319 [==============================] - 223s 699ms/step - loss: 0.1882 - accuracy: 0.4308 - val_loss: 0.1811 - val_accuracy: 0.4330\n",
      "Epoch 18/20\n",
      "319/319 [==============================] - 222s 696ms/step - loss: 0.1760 - accuracy: 0.4328 - val_loss: 0.1648 - val_accuracy: 0.4353\n",
      "Epoch 19/20\n",
      "319/319 [==============================] - 222s 695ms/step - loss: 0.1577 - accuracy: 0.4359 - val_loss: 0.1519 - val_accuracy: 0.4363\n",
      "Epoch 20/20\n",
      "319/319 [==============================] - 223s 698ms/step - loss: 0.1453 - accuracy: 0.4371 - val_loss: 0.1518 - val_accuracy: 0.4358\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2d813c6eb0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_steps=train_data.shape[0]//512\n",
    "valid_steps=validation_data.shape[0]//512\n",
    "model.fit(batch_train_data, steps_per_epoch=train_steps, epochs=20, validation_data=batch_validation_data,\n",
    "                     validation_steps=valid_steps, callbacks=[callbacks_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ZsLZ50QSOdvI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "ZsLZ50QSOdvI",
    "outputId": "205c8e3d-b764-4b6a-89e7-edfeb44a6a97"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f2d081443a0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(tf.ones(shape=(512,512,20)))\n",
    "model.load_weights(os.getcwd() + \"/bahadanau_attention_model_weights.hdf520230214-075454\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5cTeSdI7O-Rv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "5cTeSdI7O-Rv",
    "outputId": "b749be6e-929e-493e-9353-cc227edb3464"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "319/319 [==============================] - 226s 705ms/step - loss: 0.1058 - accuracy: 0.4404 - val_loss: 0.1059 - val_accuracy: 0.4391\n",
      "Epoch 2/5\n",
      "319/319 [==============================] - 224s 701ms/step - loss: 0.0978 - accuracy: 0.4411 - val_loss: 0.1014 - val_accuracy: 0.4397\n",
      "Epoch 3/5\n",
      "319/319 [==============================] - 224s 702ms/step - loss: 0.0877 - accuracy: 0.4425 - val_loss: 0.0966 - val_accuracy: 0.4398\n",
      "Epoch 4/5\n",
      "319/319 [==============================] - 222s 697ms/step - loss: 0.0928 - accuracy: 0.4411 - val_loss: 0.0995 - val_accuracy: 0.4386\n",
      "Epoch 5/5\n",
      "319/319 [==============================] - 223s 700ms/step - loss: 0.0810 - accuracy: 0.4429 - val_loss: 0.0944 - val_accuracy: 0.4389\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2d080afdf0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(batch_train_data, steps_per_epoch=train_steps, epochs=5, validation_data=batch_validation_data,\n",
    "                      validation_steps=valid_steps, callbacks=[callbacks_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d4114ee1",
   "metadata": {
    "id": "d4114ee1"
   },
   "outputs": [],
   "source": [
    "#%tensorboard --log_directory logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ef68a2dc",
   "metadata": {
    "id": "ef68a2dc"
   },
   "outputs": [],
   "source": [
    "encoder_layer = model.layers[0]\n",
    "decoder_layer = model.layers[1]\n",
    "onestepdecoder = decoder_layer.layers[0]\n",
    "\n",
    "def EncoderOutput(enc_input):\n",
    "    encoder_input=list()\n",
    "    for word in enc_input.split():\n",
    "        if perturbated_text_tokernizer_index.get(word) != None:\n",
    "            encoder_input.append(perturbated_text_tokernizer_index.get(word))\n",
    "        else:\n",
    "            encoder_input.append(0)\n",
    "    \n",
    "    encoder_input = tf.keras.preprocessing.sequence.pad_sequences([encoder_input], maxlen=20, padding='post')\n",
    "    encoder_output, encoder_hidden_state, encoder_cell_state = encoder_layer(encoder_input,0)\n",
    "    \n",
    "    return encoder_output, encoder_hidden_state, encoder_cell_state\n",
    "\n",
    "\n",
    "def PredictOutput(enc_inp, dec_inp):\n",
    "    enc_out, enc_hidden, enc_cell=EncoderOutput(enc_inp)\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_cell = enc_cell \n",
    "    translated_output=\"\"\n",
    "    dec_inp = tf.expand_dims([text_inp_tokernizer.word_index['sos']],0)\n",
    "\n",
    "    att_weights = np.zeros((1,20), dtype='float32')\n",
    "    att_weights[:,0] = 1    \n",
    "    \n",
    "    for word in range(20):\n",
    "\n",
    "            predicted, dec_hidden, dec_cell, att_weights, context_vec = onestepdecoder(dec_inp, enc_out,\n",
    "                                                                            dec_hidden, dec_cell, att_weights)        \n",
    "\n",
    "            predicted_word_index = tf.argmax(predicted[0]).numpy()\n",
    "\n",
    "            if text_inp_tokernizer.index_word[predicted_word_index] == 'eos':\n",
    "                return translated_output \n",
    "\n",
    "            translated_output = translated_output + text_inp_tokernizer.index_word[predicted_word_index] + ' '\n",
    "            dec_inp = tf.expand_dims([predicted_word_index], 0)\n",
    "\n",
    "    return translated_output\n",
    "\n",
    "def InferResults(data):\n",
    "    output = []\n",
    "\n",
    "    for enc_inp, dec_inp, dec_out in data.values:\n",
    "        pred = PredictOutput(enc_inp, dec_inp)\n",
    "        output.append(pred)\n",
    "\n",
    "    data['correct_output'] = data['dec_out']\n",
    "    data['predicted_output'] = output\n",
    "\n",
    "    data = data.drop(['dec_inp', 'dec_out'], axis=1)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def compute_blue_score(results):\n",
    "    data_output_bleu_score = []\n",
    "    for encoder_input_data, correct_output , predicted_output in results.values:\n",
    "        correct_output = correct_output.split()        \n",
    "        predicted_output = predicted_output.rstrip().split()\n",
    "        data_output_bleu_score.append(sentence_bleu([correct_output[:-1]], predicted_output))    \n",
    "    blue_score=sum(data_output_bleu_score)/len(data_output_bleu_score)\n",
    "    return blue_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a45aa805",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "a45aa805",
    "outputId": "08874958-ff00-48e4-90de-26d9a2a4f019"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLUE score for Training data is: 0.7880080846981897\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-acbd9578-e01d-478a-97bd-df3024f133b6\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enc_inp</th>\n",
       "      <th>correct_output</th>\n",
       "      <th>predicted_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85373</th>\n",
       "      <td>as your teacher mr spock is fond of saying i l...</td>\n",
       "      <td>as your teacher mr spock is fond of saying i l...</td>\n",
       "      <td>as your teacher mr spock is fond of saying i l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123494</th>\n",
       "      <td>me fall let us get some drugs</td>\n",
       "      <td>me fall let us get some drugs eos</td>\n",
       "      <td>me fall let us get some drugs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107511</th>\n",
       "      <td>you are trying to save sparazza</td>\n",
       "      <td>you are trying to save sparazza eos</td>\n",
       "      <td>you are trying to save sparazza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121157</th>\n",
       "      <td>no i will get you some tea wait till you are i...</td>\n",
       "      <td>no i will get you some tea wait till you are i...</td>\n",
       "      <td>no i will get you some tea wait till you are i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47758</th>\n",
       "      <td>it is something really important jeff</td>\n",
       "      <td>it is something really important jeff eos</td>\n",
       "      <td>it is something really important jeff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47210</th>\n",
       "      <td>what is</td>\n",
       "      <td>what is eos</td>\n",
       "      <td>what is the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141372</th>\n",
       "      <td>that is very sweet of you vaughan we care abou...</td>\n",
       "      <td>that is very sweet of you vaughan we care abou...</td>\n",
       "      <td>that is very sweet of you vaughan we care abou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22312</th>\n",
       "      <td>we will be expecting you</td>\n",
       "      <td>we will be expecting you eos</td>\n",
       "      <td>we will be expecting you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45323</th>\n",
       "      <td>how would you find it</td>\n",
       "      <td>how would you find it eos</td>\n",
       "      <td>how would you find it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70215</th>\n",
       "      <td>so how is it in there</td>\n",
       "      <td>so how is it in there eos</td>\n",
       "      <td>so how is it in there</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-acbd9578-e01d-478a-97bd-df3024f133b6')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-acbd9578-e01d-478a-97bd-df3024f133b6 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-acbd9578-e01d-478a-97bd-df3024f133b6');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                  enc_inp  \\\n",
       "85373   as your teacher mr spock is fond of saying i l...   \n",
       "123494                      me fall let us get some drugs   \n",
       "107511                    you are trying to save sparazza   \n",
       "121157  no i will get you some tea wait till you are i...   \n",
       "47758               it is something really important jeff   \n",
       "47210                                             what is   \n",
       "141372  that is very sweet of you vaughan we care abou...   \n",
       "22312                            we will be expecting you   \n",
       "45323                               how would you find it   \n",
       "70215                               so how is it in there   \n",
       "\n",
       "                                           correct_output  \\\n",
       "85373   as your teacher mr spock is fond of saying i l...   \n",
       "123494                  me fall let us get some drugs eos   \n",
       "107511                you are trying to save sparazza eos   \n",
       "121157  no i will get you some tea wait till you are i...   \n",
       "47758           it is something really important jeff eos   \n",
       "47210                                         what is eos   \n",
       "141372  that is very sweet of you vaughan we care abou...   \n",
       "22312                        we will be expecting you eos   \n",
       "45323                           how would you find it eos   \n",
       "70215                           so how is it in there eos   \n",
       "\n",
       "                                         predicted_output  \n",
       "85373   as your teacher mr spock is fond of saying i l...  \n",
       "123494                     me fall let us get some drugs   \n",
       "107511                   you are trying to save sparazza   \n",
       "121157  no i will get you some tea wait till you are i...  \n",
       "47758              it is something really important jeff   \n",
       "47210                                        what is the   \n",
       "141372  that is very sweet of you vaughan we care abou...  \n",
       "22312                           we will be expecting you   \n",
       "45323                              how would you find it   \n",
       "70215                              so how is it in there   "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data_train=train_data.sample(1000)\n",
    "results=InferResults(sample_data_train)\n",
    "blue_score=compute_blue_score(results)\n",
    "print('BLEU score for Training data is: {}'.format(blue_score))\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9A1F-aE0k2ow",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "9A1F-aE0k2ow",
    "outputId": "8e58db30-86df-4051-d22b-a755aa1bf0ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLUE score for Test data is: 0.6357362905759035\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-8aa3e7bc-991f-4d31-9f01-2cb73fad52d2\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enc_inp</th>\n",
       "      <th>correct_output</th>\n",
       "      <th>predicted_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19937</th>\n",
       "      <td>for that matter i think you will too</td>\n",
       "      <td>for that matter i think you will too eos</td>\n",
       "      <td>for that matter i think you will too</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12333</th>\n",
       "      <td>but i thought he came over to america before war</td>\n",
       "      <td>but i thought he came over to america before t...</td>\n",
       "      <td>but i thought he came over to america before t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30510</th>\n",
       "      <td>i were only asking if you are related to laval...</td>\n",
       "      <td>i was only asking if you are related to the la...</td>\n",
       "      <td>i was only asking if you are related to to the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17161</th>\n",
       "      <td>i afraid we have another problem mr president</td>\n",
       "      <td>i am afraid we have another problem mr preside...</td>\n",
       "      <td>i am afraid we have another problem mr president</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15667</th>\n",
       "      <td>steady steady all right mr scott</td>\n",
       "      <td>steady steady all right mr scott eos</td>\n",
       "      <td>steady steady all right mr scott</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10532</th>\n",
       "      <td>can we make breakaway speed</td>\n",
       "      <td>can we make breakaway speed eos</td>\n",
       "      <td>can we make breakaway speed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9605</th>\n",
       "      <td>let us</td>\n",
       "      <td>let us eos</td>\n",
       "      <td>let us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30393</th>\n",
       "      <td>i guess you do not get bothered by neighbors much</td>\n",
       "      <td>i guess you do not get bothered by neighbors m...</td>\n",
       "      <td>i guess you do not get bothered by the neighbo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9317</th>\n",
       "      <td>yes i did</td>\n",
       "      <td>yes i did eos</td>\n",
       "      <td>yes i did</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17582</th>\n",
       "      <td>nobody talking about ya moms</td>\n",
       "      <td>nobody talking about ya moms eos</td>\n",
       "      <td>nobody is talking about ya a he is</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8aa3e7bc-991f-4d31-9f01-2cb73fad52d2')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-8aa3e7bc-991f-4d31-9f01-2cb73fad52d2 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-8aa3e7bc-991f-4d31-9f01-2cb73fad52d2');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                 enc_inp  \\\n",
       "19937               for that matter i think you will too   \n",
       "12333   but i thought he came over to america before war   \n",
       "30510  i were only asking if you are related to laval...   \n",
       "17161      i afraid we have another problem mr president   \n",
       "15667                   steady steady all right mr scott   \n",
       "10532                        can we make breakaway speed   \n",
       "9605                                              let us   \n",
       "30393  i guess you do not get bothered by neighbors much   \n",
       "9317                                           yes i did   \n",
       "17582                       nobody talking about ya moms   \n",
       "\n",
       "                                          correct_output  \\\n",
       "19937           for that matter i think you will too eos   \n",
       "12333  but i thought he came over to america before t...   \n",
       "30510  i was only asking if you are related to the la...   \n",
       "17161  i am afraid we have another problem mr preside...   \n",
       "15667               steady steady all right mr scott eos   \n",
       "10532                    can we make breakaway speed eos   \n",
       "9605                                          let us eos   \n",
       "30393  i guess you do not get bothered by neighbors m...   \n",
       "9317                                       yes i did eos   \n",
       "17582                   nobody talking about ya moms eos   \n",
       "\n",
       "                                        predicted_output  \n",
       "19937              for that matter i think you will too   \n",
       "12333  but i thought he came over to america before t...  \n",
       "30510    i was only asking if you are related to to the   \n",
       "17161  i am afraid we have another problem mr president   \n",
       "15667                  steady steady all right mr scott   \n",
       "10532                       can we make breakaway speed   \n",
       "9605                                             let us   \n",
       "30393  i guess you do not get bothered by the neighbo...  \n",
       "9317                                          yes i did   \n",
       "17582                nobody is talking about ya a he is   "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data_test=test_data.sample(1000)\n",
    "results=InferResults(sample_data_test)\n",
    "blue_score=compute_blue_score(results)\n",
    "print('BLEU score for Test data is: {}'.format(blue_score))\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "aYpb-gc8j3Oa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "aYpb-gc8j3Oa",
    "outputId": "c49fff29-91b1-40b7-afc2-bc6d03916c3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLUE score for Validation data is: 0.6684386187714704\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-ab85b9f4-96ff-4439-a28e-f3545ea96f4a\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enc_inp</th>\n",
       "      <th>correct_output</th>\n",
       "      <th>predicted_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38683</th>\n",
       "      <td>do you like quotes howard</td>\n",
       "      <td>do you like quotes howard eos</td>\n",
       "      <td>do you like the pets howard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26611</th>\n",
       "      <td>you know these doctors could have settled out ...</td>\n",
       "      <td>you know these doctors could have settled out ...</td>\n",
       "      <td>you know these doctors could have settled out ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9462</th>\n",
       "      <td>joel you are a liar</td>\n",
       "      <td>joel you are a liar eos</td>\n",
       "      <td>joel you are a liar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17040</th>\n",
       "      <td>indeed they were deadly little things</td>\n",
       "      <td>indeed they are deadly little things eos</td>\n",
       "      <td>indeed they are a deadly little things</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569</th>\n",
       "      <td>this is extremely dangerous direction mr presi...</td>\n",
       "      <td>this is an extremely dangerous direction mr pr...</td>\n",
       "      <td>this is extremely dangerous direction mr presi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12204</th>\n",
       "      <td>i do not expect you to be pleasant</td>\n",
       "      <td>i do not expect you to be pleasant eos</td>\n",
       "      <td>i do not expect you to be pleasant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12901</th>\n",
       "      <td>do not you know</td>\n",
       "      <td>do not you know eos</td>\n",
       "      <td>do not you know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25754</th>\n",
       "      <td>is it me is there something i have done</td>\n",
       "      <td>is it me is there something i have done eos</td>\n",
       "      <td>is it me is there something i have done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14209</th>\n",
       "      <td>i am sorry it is these goddamned shoes i do no...</td>\n",
       "      <td>i am sorry it is these goddamned shoes i do no...</td>\n",
       "      <td>i am sorry it is these goddamned shoes i do no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18650</th>\n",
       "      <td>juliet who</td>\n",
       "      <td>juliet who eos</td>\n",
       "      <td>juliet who</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ab85b9f4-96ff-4439-a28e-f3545ea96f4a')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-ab85b9f4-96ff-4439-a28e-f3545ea96f4a button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-ab85b9f4-96ff-4439-a28e-f3545ea96f4a');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                 enc_inp  \\\n",
       "38683                          do you like quotes howard   \n",
       "26611  you know these doctors could have settled out ...   \n",
       "9462                                 joel you are a liar   \n",
       "17040              indeed they were deadly little things   \n",
       "1569   this is extremely dangerous direction mr presi...   \n",
       "12204                 i do not expect you to be pleasant   \n",
       "12901                                    do not you know   \n",
       "25754            is it me is there something i have done   \n",
       "14209  i am sorry it is these goddamned shoes i do no...   \n",
       "18650                                         juliet who   \n",
       "\n",
       "                                          correct_output  \\\n",
       "38683                      do you like quotes howard eos   \n",
       "26611  you know these doctors could have settled out ...   \n",
       "9462                             joel you are a liar eos   \n",
       "17040           indeed they are deadly little things eos   \n",
       "1569   this is an extremely dangerous direction mr pr...   \n",
       "12204             i do not expect you to be pleasant eos   \n",
       "12901                                do not you know eos   \n",
       "25754        is it me is there something i have done eos   \n",
       "14209  i am sorry it is these goddamned shoes i do no...   \n",
       "18650                                     juliet who eos   \n",
       "\n",
       "                                        predicted_output  \n",
       "38683                       do you like the pets howard   \n",
       "26611  you know these doctors could have settled out ...  \n",
       "9462                                joel you are a liar   \n",
       "17040            indeed they are a deadly little things   \n",
       "1569   this is extremely dangerous direction mr presi...  \n",
       "12204                i do not expect you to be pleasant   \n",
       "12901                                   do not you know   \n",
       "25754           is it me is there something i have done   \n",
       "14209  i am sorry it is these goddamned shoes i do no...  \n",
       "18650                                        juliet who   "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data_validation=validation_data.sample(1000)\n",
    "results=InferResults(sample_data_validation)\n",
    "blue_score=compute_blue_score(results)\n",
    "print('BLEU score for Validation data is: {}'.format(blue_score))\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "E0RO9iRfD8Mi",
   "metadata": {
    "id": "E0RO9iRfD8Mi"
   },
   "source": [
    "## Observations\n",
    "- The Bahadanau Monotonic attention model is proven to be good compared to basic encoder and decoder model\n",
    "-The model gave good BLUE score of 0.788 on Train data, 0.6357 on Test data and 0.6684 on validation data\n",
    "- To improve the model, we can add introduce more gramatical error in the data, train the model with different datasets, consider using more complex attention architecture and train on large data corpus\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
